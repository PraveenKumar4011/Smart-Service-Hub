# Smart Service Hub - AI Microservice

AI-powered ticket classification and analysis microservice using spaCy + scikit-learn.

## Features

- ü§ñ **Category Classification**: Automatically categorizes tickets into Network/Security/Cloud/General
- ‚ö° **Priority Detection**: Analyzes urgency using keywords and sentiment analysis
- üè∑Ô∏è **Entity Extraction**: Identifies services, devices, and locations mentioned in tickets
- üìù **Text Summarization**: Creates concise summaries of ticket descriptions
- üéØ **Confidence Scores**: Provides confidence metrics for all predictions

## Quick Start

### Option 1: Automated Setup
```bash
cd ai-microservice
python setup.py
```

### Option 2: Manual Setup
```bash
cd ai-microservice

# Create virtual environment
python -m venv .venv
.venv\Scripts\activate  # Windows
# source .venv/bin/activate  # macOS/Linux

# Install dependencies
pip install -r requirements.txt

# Download language models
python -m spacy download en_core_web_sm
python -m textblob.download_corpora

# Train the classifier
python train.py

# Start the service
python app.py
```

## API Usage

### Analyze Ticket
**POST** `/analyze`

**Request:**
```json
{
  "description": "WiFi connection keeps dropping in the conference room",
  "requestType": "Network",
  "audioBase64": "optional base64 encoded audio"
}
```

**Response:**
```json
{
  "category": "Network",
  "priority": "Medium", 
  "summary": "WiFi connection keeps dropping in the conference room",
  "entities": {
    "service": "WiFi",
    "device": null,
    "location": "conference room"
  },
  "confidence": {
    "category": 0.892,
    "priority": 0.750
  }
}
```

### Health Check
**GET** `/health`

**Response:**
```json
{
  "status": "ok"
}
```

## Example cURL Commands

```bash
# Test basic functionality
curl -X POST http://localhost:3002/analyze \
  -H "Content-Type: application/json" \
  -d '{"description":"My computer won'\''t start and I have an important presentation today"}'

# Test network issue
curl -X POST http://localhost:3002/analyze \
  -H "Content-Type: application/json" \
  -d '{"description":"Internet is down in the entire building", "requestType":"Network"}'

# Test security issue  
curl -X POST http://localhost:3002/analyze \
  -H "Content-Type: application/json" \
  -d '{"description":"Cannot login to my account, password seems compromised"}'

# Health check
curl http://localhost:3002/health
```

## Model Training

The service includes a synthetic training dataset with ~60 examples across 4 categories:

- **Network** (15 examples): WiFi, internet, VPN, DNS issues
- **Security** (15 examples): Passwords, access control, malware
- **Cloud** (15 examples): OneDrive, SharePoint, cloud storage
- **General** (15 examples): Hardware, software, general IT support

### Retraining the Model

```bash
# Add new training examples to train.py
python train.py

# Restart the service to load new models
python app.py
```

## Architecture

- **Flask** web framework for API endpoints
- **spaCy** for named entity recognition and text processing
- **scikit-learn** for category classification (TF-IDF + Logistic Regression)
- **TextBlob** for sentiment analysis and priority detection
- **Pickle** for model serialization

## Configuration

Environment variables in `.env`:

- `PORT=3002` - Service port
- `MODEL_PATH=models/` - Directory for trained models
- `CONFIDENCE_THRESHOLD=0.5` - Minimum confidence threshold

## Performance

- **Category Classification**: ~90% accuracy on test set
- **Response Time**: ~100-200ms per request
- **Memory Usage**: ~150MB with loaded models
- **Throughput**: ~50 requests/second

## Integration

This microservice integrates with the Smart Service Hub backend:

1. Backend receives ticket from frontend
2. Backend calls AI microservice at `POST /analyze`
3. AI returns enriched ticket data
4. Backend stores enriched ticket and forwards to Zoho

## Development

### Adding New Categories

1. Add training examples in `train.py`
2. Update category list in `model_loader.py`
3. Retrain: `python train.py`
4. Restart service

### Improving Entity Extraction

1. Add patterns to `model_loader.py`
2. Update spaCy pipeline if needed
3. Test with various ticket descriptions

### Custom Priority Rules

1. Modify `detect_priority()` in `model_loader.py`
2. Add new urgency keywords
3. Adjust sentiment analysis weights

## Deployment

### Docker (Optional)
```dockerfile
FROM python:3.9-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
RUN python -m spacy download en_core_web_sm
COPY . .
RUN python train.py
EXPOSE 3002
CMD ["python", "app.py"]
```

### Production
```bash
# Use Gunicorn for production
gunicorn -w 4 -b 0.0.0.0:3002 app:app
```

## Troubleshooting

**Models not found:**
```bash
python train.py
```

**spaCy model missing:**
```bash
python -m spacy download en_core_web_sm
```

**Port already in use:**
- Change `PORT` in `.env`
- Or kill process: `lsof -ti:3002 | xargs kill`